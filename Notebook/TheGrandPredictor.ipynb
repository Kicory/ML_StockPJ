{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kicory/ML_StockPJ/blob/master/Notebook/TheGrandPredictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zqvZUNt1O4H",
        "colab_type": "text"
      },
      "source": [
        "# 0.\n",
        "제가 train을 하고 파라미터 파일은 아마도 깃에 올리지 않을까... 생각합니다. 깃이랑 colab이랑 마운트해서 사용할 수 있는 방법이 있을까 계속 찾아봤는데 없는 것 같네요. 귀찮지만..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VduFogSU3lyo",
        "colab_type": "code",
        "outputId": "bd9b12a7-e10c-45e7-cbc4-15ac9957515c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/gdrive')\n",
        "gdrive_root = '/gdrive/My Drive'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WApKS_6D3yW2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# for teaching force\n",
        "import random\n",
        "\n",
        "# for CSV\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#from torch.utils.data import DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7H8MY2Ylg1u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(470)\n",
        "torch.cuda.manual_seed(470)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTqyB5SLlkmt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxEpoch = 30\n",
        "learningRate = 0.005\n",
        "batchSize = 4\n",
        "device = 'cuda'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec3to4uvl3gt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = os.path.join(gdrive_root, 'Project/Data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9w05MVJ34eEv",
        "colab_type": "text"
      },
      "source": [
        "# 시작하기\n",
        "이 프로젝트에서는 좀 특이한 방식으로 데이터 처리를 해야 합니다. 이유는 다음과 같습니다.\n",
        "\n",
        "pytorch.nn 의 모듈을 상속받아 만든 클래스로 어떤 모델을 만들었다고 해 봅시다. 해당 모델의 desirable input dimension이 n이라고 합시다.\n",
        "\n",
        "\n",
        "*   minibatch갯수가 1일 때: n차원의 input을 넣으면 정상 작동(당연)\n",
        "*   minibatch갯수가 2이상: n + 1차원의 input을 넣음(???)\n",
        "\n",
        "pytorch가 용하게도 input의 첫 번째 원소를 minibatch의 갯수로 인식하고 input을 minibatch 수만큼 갈라서 병렬 처리를 하는 겁니다. 그러면 input은 n차원의 minibatch개 input으로 나뉘어집니다. 이게 기본 작동 원리입니다.\n",
        "\n",
        "일반적인 방법으로 데이터를 쪼개면 이런 관례에 따라 minibatch 갯수가 첫 차원의 원소로 들어가게 됩니다. 그런데 지금 우리가 가지고 있는 데이터셋을 일반적인 방법으로 쪼갠다면 다음과 같은 모양을 하게 됩니다.\n",
        "\n",
        "*   (minibatch 수, 연속된 주식 정보 갯수, 주식 정보(5))\n",
        "\n",
        "이걸 LSTMCell에 넣으려면 (minibatch, 주식 정보(5))로 가공해서 연속적으로 넣어야 합니다. 그 말인즉슨 0번째 차원과 1번째 원소를 뒤바꿔야 하는데 이거 엄청 비효율입니다.\n",
        "\n",
        "따라서 데이터셋 가공에 신경을 써서 \n",
        "\n",
        "*   (연속된 주식 정보 갯수, minibatch 수, 주식 정보(5))\n",
        "\n",
        "으로 만들어야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJvjHEi9vHkQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 이게 되려나???\n",
        "def getInputData(theFile, length, batchSize):\n",
        "  reader = pd.read_csv(theFile, sep=',', chunksize=length * batchSize)\n",
        "  for chunk in reader:\n",
        "    yield torch.Tensor(chunk.to_numpy().reshape(batchSize, length, 5).swapaxes(0, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2sLMumA1J9H",
        "colab_type": "text"
      },
      "source": [
        "# 2. 모델 설명\n",
        "\n",
        "예를 들어 10일간의 주식 정보를 minibatch 4 개로 해서 train 한다.\n",
        "hidden size가 32다.\n",
        "*   x.size() = [10, 4, 5]\n",
        "*   h0.size(), c0.size() = [4, 32] (근데 이건 어차피 0으로 초기화되니 굳이 설정할 필요는 없..)\n",
        "*   futureRatio = 얼마만큼을 '예측할' 그래프로 할 것인지\n",
        " *   0.5라면 절반 만큼은 teacherForcing 100%, 절반은 teacherForcing 적게.\n",
        "*   TFRatio = 예측하는 그래프에서 teacherForcing이 일어날 확률.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpGVz98UmImi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GrandPredictor(nn.Module):\n",
        "  def __init__(self, hiddenSize=32):\n",
        "    super(GrandPredictor, self).__init__()\n",
        "\n",
        "    self.lstm = nn.LSTMCell(5, 32)\n",
        "    self.FCout = nn.Linear(32, 5)\n",
        "  def forward(self, x, h, c, futureRatio=0.5, TFRatio=0.5):\n",
        "    seqLen = x.size()[0]\n",
        "    output = []\n",
        "    prevPrediction = None\n",
        "    predictFrom = int(seqLen * futureRatio)\n",
        "    \n",
        "    assert(predictFrom >= 1, 'No given data, no prediction.')\n",
        "\n",
        "    for day in range(0, predictFrom):\n",
        "      h, c = self.lstm(x[day], (h, c))\n",
        "      prevPrediction = self.FCout(h)\n",
        "      output.append(prevPrediction.clone())\n",
        "    \n",
        "    for day in range(predictFrom, seqLen):\n",
        "      if random.uniform(0, 1) > TFRatio:\n",
        "        # No Teach forcing.\n",
        "        h, c = self.lstm(prevPrediction, (h, c))\n",
        "      else:\n",
        "        # Yes, Teach forcing.\n",
        "        h, c = self.lstm(x[day], (h, c))\n",
        "      \n",
        "      prevPrediction = self.FCout(h)\n",
        "      output.append(prevPrediction.clone())\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpE7Mn21rkSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictor = GrandPredictor(32)\n",
        "predictor = predictor.to(device)\n",
        "\n",
        "# Print your neural network structure\n",
        "print(predictor)\n",
        "\n",
        "optimizer = optim.SGD(predictor.parameters(), lr=learningRate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-97TtZXXt3gc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ckpt_dir = os.path.join(gdrive_root, 'Project/checkpoints')\n",
        "\n",
        "if not os.path.exists(ckpt_dir):\n",
        "  os.makedirs(ckpt_dir)\n",
        "  \n",
        "best_acc = 0.\n",
        "\n",
        "ckpt_path = os.path.join(ckpt_dir, 'lastest.pt')\n",
        "if os.path.exists(ckpt_path):\n",
        "  ckpt = torch.load(ckpt_path)\n",
        "  try:\n",
        "    predictor.load_state_dict(ckpt['predictor'])\n",
        "    optimizer.load_state_dict(ckpt['optimizer'])\n",
        "  except RuntimeError as e:\n",
        "      print('wrong checkpoint')\n",
        "  else:    \n",
        "    print('checkpoint is loaded !')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9T-hOvKuoSC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training process\n",
        "it = 0\n",
        "predictor.train()\n",
        "\n",
        "for epoch in range(maxEpoch):\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}